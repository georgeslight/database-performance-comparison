{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T11:13:58.367548Z",
     "start_time": "2024-12-13T11:13:58.345710Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import importlib\n",
    "import os\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import database\n",
    "importlib.reload(database)\n",
    "from database import Database\n",
    "\n",
    "puenkt_csv = 'data/puenkt.csv'\n",
    "load_dotenv()\n",
    "\n",
    "# Check if variables are loaded correctly\n",
    "print(f\"Source DB: {os.getenv('QDABABAV_POSTGRES_DBNAME')}\")\n",
    "print(f\"Target DB: {os.getenv('POSTGRES_DBNAME')}\")"
   ],
   "id": "89c7e7dd1b353b4e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source DB: qdababav\n",
      "Target DB: qdaba\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Load Data into my-postgres",
   "id": "330aaedc088edb62"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T11:29:07.064030Z",
     "start_time": "2024-12-13T11:13:59.669974Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import csv\n",
    "# source\n",
    "QDABABAV_POSTGRES_CONFIG = {\n",
    "    'dbname': os.getenv('QDABABAV_POSTGRES_DBNAME'),\n",
    "    'user': os.getenv('QDABABAV_POSTGRES_USER'),\n",
    "    'password': os.getenv('QDABABAV_POSTGRES_PASSWORD'),\n",
    "    'host': os.getenv('QDABABAV_POSTGRES_HOST'),\n",
    "    'port': int(os.getenv('QDABABAV_POSTGRES_PORT'))\n",
    "}\n",
    "\n",
    "# target\n",
    "POSTGRES_CONFIG = {\n",
    "    'dbname': os.getenv('POSTGRES_DBNAME'),\n",
    "    'user': os.getenv('POSTGRES_USER'),\n",
    "    'password': os.getenv('POSTGRES_PASSWORD'),\n",
    "    'host': os.getenv('POSTGRES_HOST'),\n",
    "    'port': int(os.getenv('POSTGRES_PORT'))\n",
    "}\n",
    "try:\n",
    "    source_table = 'qdababav.puenkt'\n",
    "    target_table = 'qdaba.puenkt'\n",
    "    ddl_path = './data/puenkt_ddl.sql'\n",
    "\n",
    "    # source\n",
    "    qdaba = Database(QDABABAV_POSTGRES_CONFIG, 'postgres')\n",
    "    qdaba.connect()\n",
    "    qdaba_cursor = qdaba.connection.cursor(name='source_cursor')\n",
    "    # target\n",
    "    postgres = Database(POSTGRES_CONFIG, 'postgres')\n",
    "    postgres.connect()\n",
    "    pg_cursor = postgres.connection.cursor()\n",
    "\n",
    "    # DDL\n",
    "    try:\n",
    "        with open(ddl_path, 'r') as ddl_file:\n",
    "            ddl = ddl_file.read()\n",
    "            print(\"Executing DDL\")\n",
    "            pg_cursor.execute(ddl)\n",
    "            postgres.connection.commit()\n",
    "            print(\"Schema and table created successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error executing DDL: {e}\")\n",
    "\n",
    "    qdaba_cursor.execute(f\"SELECT * FROM {source_table};\")\n",
    "    rows_fetched = 0\n",
    "\n",
    "    while True:\n",
    "        rows = qdaba_cursor.fetchmany(10000)\n",
    "        if not rows:\n",
    "            break # No more data\n",
    "\n",
    "        rows_fetched += len(rows)\n",
    "\n",
    "        insert_query = f\"INSERT INTO {target_table} VALUES ({', '.join(['%s'] * len(rows[0]))})\"\n",
    "        pg_cursor.executemany(insert_query, rows)\n",
    "        postgres.connection.commit()\n",
    "\n",
    "        print(f\"Loaded {rows_fetched} rows so far...\")\n",
    "\n",
    "    print(f\"Loaded {rows_fetched} total rows.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "finally:\n",
    "    qdaba_cursor.close()\n",
    "    qdaba.connection.close()\n",
    "    pg_cursor.close()\n",
    "    postgres.connection.close()"
   ],
   "id": "64717129a4291202",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Postgres database: qdababav\n",
      "Connected to Postgres database: qdaba\n",
      "Executing DDL\n",
      "Schema and table created successfully.\n",
      "Loaded 10000 rows so far...\n",
      "Loaded 20000 rows so far...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 55\u001B[0m\n\u001B[0;32m     52\u001B[0m rows_fetched \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(rows)\n\u001B[0;32m     54\u001B[0m insert_query \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mINSERT INTO \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtarget_table\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m VALUES (\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin([\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;250m \u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;28mlen\u001B[39m(rows[\u001B[38;5;241m0\u001B[39m]))\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m)\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m---> 55\u001B[0m \u001B[43mpg_cursor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecutemany\u001B[49m\u001B[43m(\u001B[49m\u001B[43minsert_query\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrows\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     56\u001B[0m postgres\u001B[38;5;241m.\u001B[39mconnection\u001B[38;5;241m.\u001B[39mcommit()\n\u001B[0;32m     58\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLoaded \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mrows_fetched\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m rows so far...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32mC:\\Program Files\\Python\\Python39\\lib\\encodings\\utf_8.py:15\u001B[0m, in \u001B[0;36mdecode\u001B[1;34m(input, errors)\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;66;03m### Codec APIs\u001B[39;00m\n\u001B[0;32m     13\u001B[0m encode \u001B[38;5;241m=\u001B[39m codecs\u001B[38;5;241m.\u001B[39mutf_8_encode\n\u001B[1;32m---> 15\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecode\u001B[39m(\u001B[38;5;28minput\u001B[39m, errors\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstrict\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[0;32m     16\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m codecs\u001B[38;5;241m.\u001B[39mutf_8_decode(\u001B[38;5;28minput\u001B[39m, errors, \u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01mIncrementalEncoder\u001B[39;00m(codecs\u001B[38;5;241m.\u001B[39mIncrementalEncoder):\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Postgres",
   "id": "727280a01064540c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Connect to Postgres Database",
   "id": "dacb8c7d474de431"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T16:40:53.756610Z",
     "start_time": "2024-12-12T16:40:53.691530Z"
    }
   },
   "cell_type": "code",
   "source": [
    "POSTGRES_CONFIG = {\n",
    "    'dbname': os.getenv('POSTGRES_DBNAME'),\n",
    "    'user': os.getenv('POSTGRES_USER'),\n",
    "    'password': os.getenv('POSTGRES_PASSWORD'),\n",
    "    'host': os.getenv('POSTGRES_HOST'),\n",
    "    'port': int(os.getenv('POSTGRES_PORT'))\n",
    "}\n",
    "\n",
    "postgres = Database(POSTGRES_CONFIG, 'postgres')\n",
    "postgres.connect()\n",
    "pg_cursor = postgres.connection.cursor()"
   ],
   "id": "9b21919afba3132e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Postgres\n"
     ]
    }
   ],
   "execution_count": 90
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Load Data into Postgres DB",
   "id": "5309621b30cdba8f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ddl_file = open('./data/puenkt_ddl.sql', 'r')\n",
    "with pg_cursor as conn:\n",
    "    create_schema = \"CREATE SCHEMA IF NOT EXISTS qdaba;\"\n",
    "    create_table = ddl_file.read()\n",
    "    conn.execute(create_schema)\n",
    "    conn.execute(create_table)\n",
    "    result = conn.copy_expert(f\"COPY qdaba.puenkt FROM STDIN WITH (FORMAT CSV, HEADER TRUE);\", open(f\"./{puenkt_csv}\", 'r', encoding='utf-8'))\n",
    "    postgres.connection.commit()"
   ],
   "id": "4eb546119c901d64",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "e8189d3e3cbc9378"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T16:25:27.098839Z",
     "start_time": "2024-12-12T16:25:26.973745Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sql_file_path = './data/puenktlichkeit.sql'\n",
    "\n",
    "postgres.connect()\n",
    "pg_cursor = postgres.connection.cursor()\n",
    "with pg_cursor as conn:\n",
    "    try:\n",
    "        with open(sql_file_path, 'r') as file:\n",
    "            query = file.read()\n",
    "\n",
    "        # Measure the execution time\n",
    "        start_time = time.time()\n",
    "        conn.execute(query)\n",
    "        results = conn.fetchall()\n",
    "        end_time = time.time()\n",
    "\n",
    "        # Compute the execution time\n",
    "        execution_time = end_time - start_time\n",
    "        print(f\"Query executed in {execution_time:.6f} seconds.\")\n",
    "\n",
    "        # Print the number of results and first few rows (optional)\n",
    "        print(f\"Number of results: {len(results)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error executing query: {e}\")\n"
   ],
   "id": "d29560e303557fd4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Postgres\n",
      "Query executed in 0.074382 seconds.\n",
      "Number of results: 3068\n"
     ]
    }
   ],
   "execution_count": 85
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### DuckDB",
   "id": "bc9e4205ff0539e6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Connect to DuckDB Database",
   "id": "35e1bdc8bdf1155a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T14:15:25.105069Z",
     "start_time": "2024-12-12T14:15:25.055060Z"
    }
   },
   "cell_type": "code",
   "source": [
    "DUCKDB_CONFIG = {\"filepath\": \"./data/duck.db\"}\n",
    "duck = Database(DUCKDB_CONFIG, 'duckdb')\n",
    "duck.connect()\n",
    "ddbconn = duck.connection"
   ],
   "id": "6f141d806418d270",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to DuckDB at ./data/duck.db\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Load Data into DuckDb",
   "id": "257d62d572c1d595"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T14:35:01.567297Z",
     "start_time": "2024-12-11T14:35:00.952904Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with ddbconn as conn:\n",
    "    create_schema = \"CREATE SCHEMA IF NOT EXISTS qdaba;\"\n",
    "    create_table = f\"CREATE TABLE IF NOT EXISTS qdaba.puenkt AS FROM read_csv_auto('{puenkt_csv}');\"\n",
    "    copy_table = f\"COPY qdaba.puenkt FROM '{puenkt_csv}' WITH (FORMAT CSV);\"\n",
    "    conn.execute(create_schema)\n",
    "    conn.execute(create_table)\n",
    "    result = conn.execute(copy_table)\n",
    "    print(result.fetchall())"
   ],
   "id": "1a3afc49262d3608",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(50000,)]\n"
     ]
    }
   ],
   "execution_count": 84
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Cassandra",
   "id": "7ab7f656959ad864"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Connect to Cassandra Database",
   "id": "2d9294376b94efc2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T15:35:54.942750Z",
     "start_time": "2024-12-12T15:35:49.881530Z"
    }
   },
   "cell_type": "code",
   "source": [
    "CASSANDRA_CONFIG = {\n",
    "    'host': os.getenv('CASSANDRA_HOST'),\n",
    "    'port': int(os.getenv('CASSANDRA_PORT')),\n",
    "    'keyspace': os.getenv('CASSANDRA_KEYSPACE'),\n",
    "    'username': os.getenv('CASSANDRA_USERNAME'),\n",
    "    'password': os.getenv('CASSANDRA_PASSWORD')\n",
    "}\n",
    "\n",
    "cassandra = Database(CASSANDRA_CONFIG, 'cassandra')\n",
    "cassandra.connect()\n",
    "ccconn = cassandra.session"
   ],
   "id": "b169a2dba094e6c2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Cassandra\n"
     ]
    }
   ],
   "execution_count": 68
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Load Data into Cassandra",
   "id": "f9e6b4a8cfd2fec8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T15:48:52.314968Z",
     "start_time": "2024-12-12T15:35:54.950264Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# This is too slow, have to do it in another way 12m 57s for 50.000 rows.\n",
    "ddl_file_path = './data/cassandra_puenkt_ddl.sql'\n",
    "\n",
    "with ccconn as conn:\n",
    "    with open(ddl_file_path, 'r') as file:\n",
    "        ddl_statements = file.read()\n",
    "        conn.execute(ddl_statements)\n",
    "\n",
    "    data = pd.read_csv(puenkt_csv, dtype={'id_anwendungsfall': str, 'id_fahrt_tu': str, 'id_verspcode': str, 'id_fahrt': str})\n",
    "    insert_query = (f\"INSERT INTO puenkt(\"\n",
    "                    f\"id_t_puenkt, id_linie_tu, id_fahrt, betriebstag, fahrt_halt_lauf, go_nr, id_an_ab, id_anwendungsfall, id_fahrt_tu, id_messpunkt, id_mvu, id_t_import, id_t_linie_bav, id_t_puenkt_fahrt, id_verspcode, insert_time, ist_tu, manipulation_time, qrelevant, soll_bav, soll_tu) \"\n",
    "                    f\"VALUES (\"\n",
    "                    f\"%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\")\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        # Replace NaN or null strings with None for Cassandra\n",
    "        row['id_verspcode'] = row['id_verspcode'] if pd.notna(row['id_verspcode']) else None\n",
    "        row['manipulation_time'] = row['manipulation_time'] if pd.notna(row['manipulation_time']) else None\n",
    "\n",
    "        conn.execute(insert_query, (\n",
    "                row['id_t_puenkt'],\n",
    "                row['id_linie_tu'],\n",
    "                row['id_fahrt'],\n",
    "                row['betriebstag'],\n",
    "                row['fahrt_halt_lauf'],\n",
    "                row['go_nr'],\n",
    "                row['id_an_ab'],\n",
    "                row['id_anwendungsfall'],\n",
    "                row['id_fahrt_tu'],\n",
    "                row['id_messpunkt'],\n",
    "                row['id_mvu'],\n",
    "                row['id_t_import'],\n",
    "                row['id_t_linie_bav'],\n",
    "                row['id_t_puenkt_fahrt'],\n",
    "                row['id_verspcode'],\n",
    "                row['insert_time'],\n",
    "                row['ist_tu'],\n",
    "                row['manipulation_time'],\n",
    "                row['qrelevant'],\n",
    "                row['soll_bav'],\n",
    "                row['soll_tu']\n",
    "            )\n",
    "        )\n",
    "\n",
    "    print(\"Data loaded into Cassandra\")\n"
   ],
   "id": "6c3ac612eb7745dd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded into Cassandra\n"
     ]
    }
   ],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T15:48:52.406630Z",
     "start_time": "2024-12-12T15:48:52.390796Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "2de7b7c797e988b8",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
